{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c88228c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedGroupKFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn_rvm import EMRVR\n",
    "\n",
    "import shap\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#Set random seed to current date and time to get a pseudorandom state\n",
    "import random\n",
    "from datetime import datetime\n",
    "random.seed(datetime.now()) \n",
    "\n",
    "#This is to round the output to 3 decimal places when printing outputs\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "#Import dataset\n",
    "data = pd.read_csv(\"C:/Users/kimng/Desktop/ML - Age, Hipp, CVLT/CVLTHippocampus.csv\")\n",
    "data = data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92bcab8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select columns to be used for analyses\n",
    "columns = ['CVLT_Imm_Total', 'CVLT_DelR_SD_Free', 'CVLT_DelR_LD_Free',\n",
    "            'Age','Sex', 'EduYears', 'Smoker', 'High_BP', 'COMT', 'BDNF2', 'ApoE4',\n",
    "           'L_HH_Total', 'R_HH_Total', 'L_HB_Total', 'R_HB_Total', 'L_HT_Total', 'R_HT_Total',\n",
    "           'L_DG_Total', 'R_DG_Total',\n",
    "           'L_CA_Total', 'R_CA_Total',\n",
    "           'L_Sub_Total', 'R_Sub_Total',\n",
    "           'L_HH_CA', 'R_HH_CA', 'L_HB_CA', 'R_HB_CA', 'L_HT_CA', 'R_HT_CA', \n",
    "           'L_HH_DG', 'R_HH_DG', 'L_HB_DG', 'R_HB_DG', 'L_HT_DG', 'R_HT_DG',\n",
    "           'L_HH_Sub', 'R_HH_Sub', 'L_HB_Sub', 'R_HB_Sub', 'L_HT_Sub', 'R_HT_Sub']\n",
    "\n",
    "#Subset data\n",
    "df = data[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c1a2d58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(129, 41)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop missing data list-wise\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "#reset index -- this is to replace old data index with index based on current data.\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# get new data dimension\n",
    "df.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a3436f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Sex = df.Sex-1 #Change Sex from 1,2 to 0,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc75b236",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bin Age into groups\n",
    "bins = [10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
    "labels = [1,2,3,4,5,6,7,8]\n",
    "df['AgeGroup'] = pd.cut(df['Age'], bins=bins, labels=labels)\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "#Function for categorise dataframe\n",
    "def categorise(row):\n",
    "    if row['AgeGroup'] == 1 and row['Sex'] == 0:\n",
    "        return 1\n",
    "    elif row['AgeGroup'] == 1 and row['Sex'] == 1:\n",
    "        return 2\n",
    "    elif row['AgeGroup'] == 2 and row['Sex'] == 0:\n",
    "        return 3\n",
    "    elif row['AgeGroup'] == 2 and row['Sex'] == 1:\n",
    "        return 4\n",
    "    elif row['AgeGroup'] == 3 and row['Sex'] == 0:\n",
    "        return 5\n",
    "    elif row['AgeGroup'] == 3 and row['Sex'] == 1:\n",
    "        return 6\n",
    "    elif row['AgeGroup'] == 4 and row['Sex'] == 0:\n",
    "        return 7\n",
    "    elif row['AgeGroup'] == 4 and row['Sex'] == 1:\n",
    "        return 8\n",
    "    elif row['AgeGroup'] == 5 and row['Sex'] == 0:\n",
    "        return 9\n",
    "    elif row['AgeGroup'] == 5 and row['Sex'] == 1:\n",
    "        return 10\n",
    "    elif row['AgeGroup'] == 6 and row['Sex'] == 0:\n",
    "        return 11\n",
    "    elif row['AgeGroup'] == 6 and row['Sex'] == 1:\n",
    "        return 12\n",
    "    elif row['AgeGroup'] == 7 and row['Sex'] == 0:\n",
    "        return 13\n",
    "    elif row['AgeGroup'] == 7 and row['Sex'] == 1:\n",
    "        return 14\n",
    "    elif row['AgeGroup'] == 8 and row['Sex'] == 0:\n",
    "        return 15\n",
    "    elif row['AgeGroup'] == 8 and row['Sex'] == 1:\n",
    "        return 16\n",
    "\n",
    "\n",
    "#Apply categories to dataframe\n",
    "df['grp'] = df.apply(lambda row: categorise(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abeb7039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CVLT_Imm_Total</th>\n",
       "      <th>CVLT_DelR_SD_Free</th>\n",
       "      <th>CVLT_DelR_LD_Free</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>EduYears</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>High_BP</th>\n",
       "      <th>COMT</th>\n",
       "      <th>BDNF2</th>\n",
       "      <th>...</th>\n",
       "      <th>R_HB_DG</th>\n",
       "      <th>L_HT_DG</th>\n",
       "      <th>R_HT_DG</th>\n",
       "      <th>L_HH_Sub</th>\n",
       "      <th>R_HH_Sub</th>\n",
       "      <th>L_HB_Sub</th>\n",
       "      <th>R_HB_Sub</th>\n",
       "      <th>L_HT_Sub</th>\n",
       "      <th>R_HT_Sub</th>\n",
       "      <th>grp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>129.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>129.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>54.775194</td>\n",
       "      <td>11.666667</td>\n",
       "      <td>12.248062</td>\n",
       "      <td>47.635659</td>\n",
       "      <td>0.542636</td>\n",
       "      <td>15.860465</td>\n",
       "      <td>1.031008</td>\n",
       "      <td>1.116279</td>\n",
       "      <td>2.062016</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>312.167117</td>\n",
       "      <td>215.278658</td>\n",
       "      <td>216.086355</td>\n",
       "      <td>270.114788</td>\n",
       "      <td>286.853054</td>\n",
       "      <td>216.401042</td>\n",
       "      <td>208.797596</td>\n",
       "      <td>26.868606</td>\n",
       "      <td>29.594662</td>\n",
       "      <td>8.054264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.126062</td>\n",
       "      <td>2.608080</td>\n",
       "      <td>2.613161</td>\n",
       "      <td>18.883251</td>\n",
       "      <td>0.500121</td>\n",
       "      <td>2.461403</td>\n",
       "      <td>0.174014</td>\n",
       "      <td>0.321809</td>\n",
       "      <td>0.736885</td>\n",
       "      <td>0.473242</td>\n",
       "      <td>...</td>\n",
       "      <td>56.639130</td>\n",
       "      <td>55.946779</td>\n",
       "      <td>57.863672</td>\n",
       "      <td>54.831992</td>\n",
       "      <td>53.460985</td>\n",
       "      <td>41.213681</td>\n",
       "      <td>35.336911</td>\n",
       "      <td>6.789627</td>\n",
       "      <td>8.055470</td>\n",
       "      <td>3.863511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>173.639405</td>\n",
       "      <td>89.231806</td>\n",
       "      <td>89.795907</td>\n",
       "      <td>148.819290</td>\n",
       "      <td>158.846793</td>\n",
       "      <td>110.909966</td>\n",
       "      <td>106.781205</td>\n",
       "      <td>12.233782</td>\n",
       "      <td>15.553328</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>49.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>271.435985</td>\n",
       "      <td>174.712057</td>\n",
       "      <td>181.698029</td>\n",
       "      <td>229.770510</td>\n",
       "      <td>254.843688</td>\n",
       "      <td>186.129439</td>\n",
       "      <td>187.518921</td>\n",
       "      <td>22.200925</td>\n",
       "      <td>24.290453</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>55.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>313.215662</td>\n",
       "      <td>213.735190</td>\n",
       "      <td>209.295573</td>\n",
       "      <td>265.785139</td>\n",
       "      <td>285.320587</td>\n",
       "      <td>215.537167</td>\n",
       "      <td>209.140882</td>\n",
       "      <td>24.817369</td>\n",
       "      <td>28.900795</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>61.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>349.277249</td>\n",
       "      <td>254.920021</td>\n",
       "      <td>254.615139</td>\n",
       "      <td>310.839873</td>\n",
       "      <td>317.390520</td>\n",
       "      <td>243.406118</td>\n",
       "      <td>230.304132</td>\n",
       "      <td>31.469792</td>\n",
       "      <td>33.466886</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>73.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>455.998451</td>\n",
       "      <td>352.813403</td>\n",
       "      <td>363.037216</td>\n",
       "      <td>433.877967</td>\n",
       "      <td>494.619458</td>\n",
       "      <td>332.358149</td>\n",
       "      <td>305.395180</td>\n",
       "      <td>46.911832</td>\n",
       "      <td>55.632057</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       CVLT_Imm_Total  CVLT_DelR_SD_Free  CVLT_DelR_LD_Free         Age  \\\n",
       "count      129.000000         129.000000         129.000000  129.000000   \n",
       "mean        54.775194          11.666667          12.248062   47.635659   \n",
       "std          9.126062           2.608080           2.613161   18.883251   \n",
       "min         35.000000           6.000000           5.000000   18.000000   \n",
       "25%         49.000000          10.000000          10.000000   30.000000   \n",
       "50%         55.000000          12.000000          12.000000   48.000000   \n",
       "75%         61.000000          14.000000          14.000000   64.000000   \n",
       "max         73.000000          16.000000          16.000000   85.000000   \n",
       "\n",
       "              Sex    EduYears      Smoker     High_BP        COMT       BDNF2  \\\n",
       "count  129.000000  129.000000  129.000000  129.000000  129.000000  129.000000   \n",
       "mean     0.542636   15.860465    1.031008    1.116279    2.062016    1.666667   \n",
       "std      0.500121    2.461403    0.174014    0.321809    0.736885    0.473242   \n",
       "min      0.000000   10.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "25%      0.000000   14.000000    1.000000    1.000000    2.000000    1.000000   \n",
       "50%      1.000000   16.000000    1.000000    1.000000    2.000000    2.000000   \n",
       "75%      1.000000   17.000000    1.000000    1.000000    3.000000    2.000000   \n",
       "max      1.000000   23.000000    2.000000    2.000000    3.000000    2.000000   \n",
       "\n",
       "       ...     R_HB_DG     L_HT_DG     R_HT_DG    L_HH_Sub    R_HH_Sub  \\\n",
       "count  ...  129.000000  129.000000  129.000000  129.000000  129.000000   \n",
       "mean   ...  312.167117  215.278658  216.086355  270.114788  286.853054   \n",
       "std    ...   56.639130   55.946779   57.863672   54.831992   53.460985   \n",
       "min    ...  173.639405   89.231806   89.795907  148.819290  158.846793   \n",
       "25%    ...  271.435985  174.712057  181.698029  229.770510  254.843688   \n",
       "50%    ...  313.215662  213.735190  209.295573  265.785139  285.320587   \n",
       "75%    ...  349.277249  254.920021  254.615139  310.839873  317.390520   \n",
       "max    ...  455.998451  352.813403  363.037216  433.877967  494.619458   \n",
       "\n",
       "         L_HB_Sub    R_HB_Sub    L_HT_Sub    R_HT_Sub         grp  \n",
       "count  129.000000  129.000000  129.000000  129.000000  129.000000  \n",
       "mean   216.401042  208.797596   26.868606   29.594662    8.054264  \n",
       "std     41.213681   35.336911    6.789627    8.055470    3.863511  \n",
       "min    110.909966  106.781205   12.233782   15.553328    1.000000  \n",
       "25%    186.129439  187.518921   22.200925   24.290453    4.000000  \n",
       "50%    215.537167  209.140882   24.817369   28.900795    8.000000  \n",
       "75%    243.406118  230.304132   31.469792   33.466886   11.000000  \n",
       "max    332.358149  305.395180   46.911832   55.632057   16.000000  \n",
       "\n",
       "[8 rows x 42 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab9e2bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize Regressor\n",
    "model = EMRVR()\n",
    "\n",
    "#Set up parameter grid\n",
    "param_grid = [{\n",
    "                'gamma': ['scale', 'auto'], \n",
    "                'kernel': ['linear', 'poly', 'rbf'], \n",
    "                'degree': [1,2,3,4,5,6]}]\n",
    "\n",
    "#Set up GridSearchCV\n",
    "search = GridSearchCV(estimator=model, \n",
    "                      param_grid = param_grid,\n",
    "                      scoring = 'neg_mean_squared_error', #use MSE for model selection (larger neg-MSE = better model)\n",
    "                      cv = 3, \n",
    "                      n_jobs = 1, \n",
    "                      refit = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f533d164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Results for outer loop fold 1\n",
      "        Best MSE (inner validation folds): 62.94202893510055\n",
      "        Best parameters: {'degree': 1, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "        MSE (on outer training fold) 47.040048400735635\n",
      "        MSE (on outer test fold) 78.42037175944469\n",
      "        RMSE (on outer test fold) 8.855527751604908\n",
      "        MAE (on outer test fold) 7.7682684001215225\n",
      "        R2 (on outer validation fold) 0.2858293751851081\n",
      "        Predicted vs actual values correlation (on outer test fold) 0.5725463179300909\n",
      "\n",
      " Results for outer loop fold 2\n",
      "        Best MSE (inner validation folds): 67.12999213475985\n",
      "        Best parameters: {'degree': 2, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "        MSE (on outer training fold) 49.680374257035645\n",
      "        MSE (on outer test fold) 70.50806729663334\n",
      "        RMSE (on outer test fold) 8.39690819865463\n",
      "        MAE (on outer test fold) 6.55078524645468\n",
      "        R2 (on outer validation fold) 0.08641697668243231\n",
      "        Predicted vs actual values correlation (on outer test fold) 0.4576022277709183\n",
      "\n",
      " Results for outer loop fold 3\n",
      "        Best MSE (inner validation folds): 66.85500733631297\n",
      "        Best parameters: {'degree': 1, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "        MSE (on outer training fold) 50.59883625345759\n",
      "        MSE (on outer test fold) 69.4255270740918\n",
      "        RMSE (on outer test fold) 8.332198213802394\n",
      "        MAE (on outer test fold) 6.829166549432179\n",
      "        R2 (on outer validation fold) 0.17298131560431995\n",
      "        Predicted vs actual values correlation (on outer test fold) 0.43859626695378207\n",
      "\n",
      " Results for outer loop fold 4\n",
      "        Best MSE (inner validation folds): 57.021921939039714\n",
      "        Best parameters: {'degree': 1, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "        MSE (on outer training fold) 43.5901481621555\n",
      "        MSE (on outer test fold) 77.77514312052902\n",
      "        RMSE (on outer test fold) 8.819021664591205\n",
      "        MAE (on outer test fold) 7.2915410257270645\n",
      "        R2 (on outer validation fold) 0.13430924292431423\n",
      "        Predicted vs actual values correlation (on outer test fold) 0.3784948620047545\n",
      "\n",
      " Results for outer loop fold 5\n",
      "        Best MSE (inner validation folds): 72.70958189292722\n",
      "        Best parameters: {'degree': 1, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "        MSE (on outer training fold) 54.45482327428306\n",
      "        MSE (on outer test fold) 36.58691695219961\n",
      "        RMSE (on outer test fold) 6.048712007708716\n",
      "        MAE (on outer test fold) 4.906723601277955\n",
      "        R2 (on outer validation fold) 0.21998829665968211\n",
      "        Predicted vs actual values correlation (on outer test fold) 0.5093653539146328\n",
      "\n",
      "    Average performance across all outer loops:\n",
      "        MSE 66.54 +/- 15.42\n",
      "        RMSE 8.09 +/- 1.04\n",
      "        MAE 6.67 +/- 0.97\n",
      "        R2 0.18 +/- 0.07\n",
      "        Correlation 0.47 +/- 0.07\n"
     ]
    }
   ],
   "source": [
    "# Empty list to store evaluation metrics\n",
    "outer_scores_mae = []\n",
    "outer_scores_mse = []\n",
    "outer_scores_rmse = []\n",
    "outer_scores_corelation = []\n",
    "outer_scores_r2 = []\n",
    "\n",
    "\n",
    "feature_names = ['Age','Sex', 'EduYears', 'Smoker', 'High_BP', 'COMT', 'BDNF2', 'ApoE4',\n",
    "                 'L_HH_Total', 'R_HH_Total', 'L_HB_Total', 'R_HB_Total', 'L_HT_Total', 'R_HT_Total',\n",
    "                 'L_DG_Total', 'R_DG_Total',\n",
    "                 'L_CA_Total', 'R_CA_Total',\n",
    "                 'L_Sub_Total', 'R_Sub_Total',\n",
    "                 'L_HH_CA', 'R_HH_CA', 'L_HB_CA', 'R_HB_CA', 'L_HT_CA', 'R_HT_CA', \n",
    "                 'L_HH_DG', 'R_HH_DG', 'L_HB_DG', 'R_HB_DG', 'L_HT_DG', 'R_HT_DG',\n",
    "                 'L_HH_Sub', 'R_HH_Sub', 'L_HB_Sub', 'R_HB_Sub', 'L_HT_Sub', 'R_HT_Sub']\n",
    "target = ['CVLT_Imm_Total']\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = MinMaxScaler()\n",
    "df[feature_names] = scaler.fit_transform(df[feature_names])\n",
    "\n",
    "# configure the cross-validation procedure\n",
    "outer_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=0) \n",
    "\n",
    "#fold counter\n",
    "fold_no = 1\n",
    "\n",
    "# Loop through each outer CV fold\n",
    "for train_index_outer, test_index_outer in outer_cv.split(df, df.grp):\n",
    "    train_set = df.loc[train_index_outer,:]\n",
    "    test_set = df.loc[test_index_outer,:]\n",
    "\n",
    "    X_train = train_set[feature_names]\n",
    "    y_train = train_set[target]\n",
    "    X_test = test_set[feature_names]\n",
    "    y_test = test_set[target]\n",
    "    \n",
    "        \n",
    "    print(\"\\n Results for outer loop fold\", fold_no)\n",
    "    fold_no = fold_no+1\n",
    "        \n",
    "    \n",
    "    #Print out memory performance to ensure similar distribution across folds\n",
    "#    plt.figure()\n",
    "#    plt.subplot(1, 2, 1) \n",
    "#    plt.hist(y_train, bins=10)\n",
    "#    plt.hist(y_test, bins=10)\n",
    "#    plt.title(\"Memory Score Distribution\")\n",
    "    \n",
    "#    plt.subplot(1, 2, 2)\n",
    "#    plt.hist(X_train.Age, bins=10)\n",
    "#    plt.hist(X_test.Age, bins=10)\n",
    "#    plt.title(\"Age Distribution\")\n",
    "    \n",
    "#    plt.show()\n",
    "    \n",
    "    #Apply grid search with CV=3 on outer train_set (this is hyperparameter tuning process within the inner loop)\n",
    "    search.fit(X = X_train, y = y_train) # run inner loop hyperparam tuning\n",
    "\n",
    "    print('        Best MSE (inner validation folds):', abs(search.best_score_))\n",
    "    print('        Best parameters:', search.best_params_)\n",
    "    \n",
    "    #Best model based on grid search\n",
    "    best_model = search.best_estimator_\n",
    "   \n",
    "    #Inner Train set performance\n",
    "    #This is to compare with performance on the test set and identify fitting issues\n",
    "    y_train_hat = best_model.predict(X_train)\n",
    "    mse_train = mean_squared_error(y_train, y_train_hat)\n",
    "    print('        MSE (on outer training fold)', mse_train)\n",
    "    \n",
    "    #Predict y_test based on best model\n",
    "    y_test_hat = best_model.predict(X_test)\n",
    "    \n",
    "    # Calculate evaluation metrics using best-tuned model on the outer val_set  \n",
    "    #MSE\n",
    "    mse_test = mean_squared_error(y_test, y_test_hat)\n",
    "    outer_scores_mse.append(mse_test)\n",
    "    print('        MSE (on outer test fold)', (outer_scores_mse[-1]))\n",
    "    \n",
    "    #RMSE\n",
    "    rmse_test = np.sqrt(mse_test)\n",
    "    outer_scores_rmse.append(rmse_test)\n",
    "    print('        RMSE (on outer test fold)', (outer_scores_rmse[-1]))\n",
    "\n",
    "    # MAE\n",
    "    mae_test = mean_absolute_error(y_test, y_test_hat)\n",
    "    outer_scores_mae.append(mae_test)          \n",
    "    print('        MAE (on outer test fold)', (outer_scores_mae[-1]))\n",
    "         \n",
    "    # R2\n",
    "    r2_test = r2_score(y_test, y_test_hat)\n",
    "    outer_scores_r2.append(r2_test)    \n",
    "    print('        R2 (on outer validation fold)', (outer_scores_r2[-1]))\n",
    "    \n",
    "    #Correlation between true vs predicted\n",
    "    y_test_array = np.array(y_test).reshape(1,len(y_test))\n",
    "    y_test_hat_array = pd.DataFrame(y_test_hat)\n",
    "    y_test_hat_array = np.array(y_test_hat_array).reshape(1,len(y_test_hat))\n",
    "    corelation_true_pred = np.corrcoef(y_test_array, y_test_hat_array)[0,1]\n",
    "    outer_scores_corelation.append(corelation_true_pred)          \n",
    "    print('        Predicted vs actual values correlation (on outer test fold)', (outer_scores_corelation[-1]))\n",
    "\n",
    "# Print evaluation metrics across all outer loop folds\n",
    "print('\\n    Average performance across all outer loops:')\n",
    "print('        MSE %.2f +/- %.2f'% (np.mean(outer_scores_mse), np.std(outer_scores_mse)))\n",
    "print('        RMSE %.2f +/- %.2f'% (np.mean(outer_scores_rmse), np.std(outer_scores_rmse)))\n",
    "print('        MAE %.2f +/- %.2f'% (np.mean(outer_scores_mae), np.std(outer_scores_mae)))\n",
    "print('        R2 %.2f +/- %.2f'% (np.mean(outer_scores_r2), np.std(outer_scores_r2)))\n",
    "print('        Correlation %.2f +/- %.2f'% (np.mean(outer_scores_corelation), np.std(outer_scores_corelation)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
